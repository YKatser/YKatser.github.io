<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<title>Notes</title>
		<meta name="description" content="">
		<meta name="author" content="">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link href='https://fonts.googleapis.com/css?family=Roboto:400,300,100,500,700&subset=latin,cyrillic' rel='stylesheet' type='text/css'>
		<link rel="stylesheet" href="css/base.css">
		<link rel="stylesheet" href="css/custom.css">
		<script src="https://use.fontawesome.com/12100a7f0e.js"></script>
	</head>
	
	
	
	<body>
		<div class="page-1">
			<div class="container">
				<div class="row">
					<div class="three col">
						<a href="http://qrcoder.ru" target="_blank"><img src="http://qrcoder.ru/code/?BEGIN%3AVCARD%0AN%3A%CA%E0%F6%E5%F0%3B%DE%F0%E8%E9%0AORG%3AWaico%2C+Inc%0ATITLE%3ACo-Founder%0ATEL%3A%2B79636767027%0AURL%3Ahttps%3A%2F%2Fwaico.github.io%0AEMAIL%3Akasteryuriy%40gmail.com%0ANOTE%3ACV%3A+Ykatser.github.io%0AEND%3AVCARD&10&0" width="210" height="210" border="0" title="QR код"></a>
					</div>
					<div class="four col">
						<ul>
							<li>CV: <a href="https://ykatser.github.io">ykatser.github.io</a>
							<li>preparing for a DS interview: <a href="https://www.datascienceweekly.org/articles/basic-research-you-must-do-before-a-data-science-interview">ten steps</a>
						</ul>
					</div>
				</div>
			</div>
		</div>
		<div class="page-1">
			<div class="container">
				<div class="row">
					<div class="twelve col tit">
						<h1>
							Books links
						</h1>
					</div>
				</div>
				<p>
					YCombinator 2017 course:
					<a href="https://www.youtube.com/watch?v=ZoqgAy3h4OM&list=PLQ-uHSnFig5MiLRb-l6yiCBGyqfVyVf17">youtube</a>
				</p>
				<p>
					YCombinator 2017 course (with russian subtitles from RUSSOL and rusbase):
					<a href="https://rb.ru/startupschool/">rusbase</a>
				</p>
				<p>
					Harvard Business Review:
					<a href="https://hbr.org">site</a>
				</p>
				<p>
					http://libgen.is/:
					<a href="http://libgen.is/">Books free downloading service</a>
				</p>
				<p>
					Podcasts:
					<a href="https://www.npr.org/programs/">link</a>
				</p>
				<p>
					Агрегатор всех источников поддержки вашего бизнеса:
					<a href="https://rb.ru/chance/">Rusbase</a>
				</p>
				<p>
					All IAEA publications: 
					<a href="https://www.iaea.org/publications/search?keywords=">All techical reviews, etc</a>
				</p>
				<p>
					Bayesian Inference & Graphical Models (by Vetrov):
					Koller09
				</p>
				<p>
					Latent Variable Models (by Vetrov):
					Bishop06
				</p>
				<p>
					A lot of ML competitions (from kaggle, drivendata, zindi, etc.):
					<a href="http://mltrainings.ru">ods site</a>
				</p>
			</div>
		</div>
		
		
		
		<div class="page-2">
			<div class="container">	
				<div class="row">
					<div class="twelve col tit">
						<h1>
							Data science
						</h1>
					</div>
				</div>
				<p>
					Data Science Resources:
					<a href="https://www.datascienceweekly.org/data-science-resources">datascienceweekly.org (till 2014)</a>
				</p>
				<p>
					About ML (a lot of the links, in Russian):
					<a href="http://www.machinelearning.ru/wiki/index.php?title=Machine_Learning">machinelearning.ru</a>
				</p>
				<p>
					Over 200 of the Best Machine Learning, NLP, and Python Tutorials — 2018 Edition (MIT's Les Fridman recommendation):
					<a href="https://medium.com/machine-learning-in-practice/over-200-of-the-best-machine-learning-nlp-and-python-tutorials-2018-edition-dd8cf53cb7dc">Medium</a>
				</p>
				<p>
					Neural networks zoo:
					<a href="http://www.asimovinstitute.org/neural-network-zoo/">link</a>
				</p>
				<p>
					70 links on ML (for beginners):
					<a href="https://habr.com/en/company/spbifmo/blog/276479/">habr</a>
				</p>
				<p>
					Deep Learning presentation by Sapunov (intento):
					<a href="http://bioinformaticsinstitute.ru/sites/default/files/vvedenie_v_deep_learning.pdf">Presentation</a> | 
					<a href="https://habr.com/ru/company/oleg-bunin/blog/340184/">Text</a>
				</p>
				<p>
					AutoML (NN):
					<a href="https://arxiv.org/abs/1806.09055">DARTS: Differentiable Architecture Search (Arxiv)</a> | 
					<a href="https://github.com/quark0/darts">github</a>
				</p>
				<p>	
					AutoKeras:
					<a href="https://arxiv.org/abs/1806.10282">arxiv</a>
				</p>
				<p>	
					Models stacking:
					<a href="https://dyakonov.org/2017/03/10/cтекинг-stacking-и-блендинг-blending/">Dyakonov</a> | 
					<a href="https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python" target="_blank">kaggle</a>
				</p>
				<p>	
					Кросс-валидация с оценкой значимости изменения и обработкой выбросов (Данила Савенков):
					<a href="https://www.youtube.com/watch?v=HT3QpRp2ewA">youtube (Kaggle Mercedes Benz)</a>
				</p>
				<p>	
					Convert a Time Series to a Supervised Learning Problem:
					<a href="https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/">machinelearningmastery.com</a>
				</p>
				<p>	
					Irregular time series and how to whip them:
					<a href="https://www.youtube.com/watch?v=E4NMZyfao2c">youtube</a>
				</p>
				<p>	
					LSTM:
					<a href="https://www.altumintelligence.com/articles/a/Time-Series-Prediction-Using-LSTM-Deep-Neural-Networks">about+code</a> | 
					<a href="https://www.youtube.com/watch?v=QbXVUHhZVVY&feature=youtu.be">youtube (Kaspersky presentational)</a> | 
					<a href="https://arxiv.org/pdf/1612.06676.pdf">arxiv (Kaspersky)</a> | 
					<a href="https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/">code (Forecasting with LSTMs in Keras)</a> | 
					<a href="https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/">code (LSTM Models)</a> | 
					<a href="http://localhost:8888/notebooks/Dropbox/Forecasting/Time%20Series/LSTM.ipynb">notebook (local)</a> | 
					<a href="https://machinelearningmastery.com/lstm-autoencoders/">AE based on LSTM</a> | 
					<a href="https://www.youtube.com/watch?v=_vQ0W_qXMxk">VAR vs LSTM</a>
				</p>
				<p>	
					Python : How to Save and Load ML Models:
					<a href="https://www.kaggle.com/prmohanty/python-how-to-save-and-load-ml-models/">kaggle article</a>
				</p>
				<p>	
					Data preprocessing for machine learning: options and recommendations (by google):
					<a href="https://cloud.google.com/solutions/machine-learning/data-preprocessing-for-ml-with-tf-transform-pt1">cloud.google.com</a>
				</p>
				<img src="docs/cv_scheme.png" alt="Simply Easy Learning" width="600" height="300">
				<p>
	         		CV scheme
					<a href="https://www.youtube.com/watch?v=AhBEBZRtpx0">(McKinsey’s Datathon: The City Cup) — Валентина Бирюкова</a>
				</p>
				
				<hr>
					
				<h3>
					Courses
				</h3>
				<p>
					Online courses and other DL staff (MIT's Les Fridman recommendation):
					<a href="https://www.fast.ai">fast.ai</a>
				</p>
				<p>
					D. Vetrov Байесовский подход к теории вероятностей. Байесовские рассуждения. Понятие о графических моделях. (поверхностный курс):
					<a href="https://www.youtube.com/watch?v=sZxE-BrSMAE">youtube</a>
				</p>
				<p>
					D. Vetrov course on Bayesian methods in ML:
					<a href="https://www.youtube.com/watch?v=Ejsr3S79gcQ">youtube</a>
				</p>
				<p>
					K. Vorontsov course on ML:
					<a href="http://www.ccas.ru/voron/teaching.html#ML">site (2007)</a>
				</p>
				<p>
					E. Sokolov course on ML (semi-beginners):
					<a href="https://github.com/esokolov/ml-course-hse/tree/master/2016-fall/lecture-notes">github</a>
				</p>
				<p>
					Statistical forecasting: notes on regression and time series analysis:
					<a href="https://people.duke.edu/~rnau/411home.htm">duke</a>
				</p>
				<p>
					Andrew Ng Deep learning on youtube:
					<a href="https://www.youtube.com/watch?v=PySo_6S4ZAg">youtube</a>
				</p>
				<p>
					✅Andrew Ng anomaly detection course:
					<a href="https://www.youtube.com/playlist?list=PLwgXNx7TiGV6UH3aEzmdZwzFRwvEnRb0N">youtube</a>
				</p>
				
				<hr>
					
				<h3>
					Notebooks links
				</h3>
				<p>
					COMPREHENSIVE DATA EXPLORATION WITH PYTHON:
					<a href="https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python">kaggle</a>
				</p>
				<p>
					ML Boot Camp II:
					<a href="https://habr.com/en/company/mailru/blog/321016/">model selection (hyperopt), feature engineering, ensembling</a>
				</p>
				<p>
					SIMPLE Feature Engineering Techniques (NAN processing, Label Encode/ Factorize/ Memory reduction, Categorical Features, Splitting, Combining / Transforming / Interaction, Aggregations / Group Statistics):
					<a href="https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575#latest-631133">kaggle</a>
				</p>
				<p>
					Statistical Learning Tutorial for Beginners (incl. CDF):
					<a href="https://www.kaggle.com/kanncaa1/statistical-learning-tutorial-for-beginners">kaggle</a>
				</p>
				<p>
					handling categorical variables:
					<a href="https://github.com/open-data-science/datascience-swiss-knife/tree/master/handling%20categorical%20variables">github</a>
				</p>
				<p>
					Bayesian Hyperparameters optimisation:
					<a href="https://github.com/open-data-science/datascience-swiss-knife/blob/master/hyperparameters%20optimization/Bayesian%20optimization%20with%20BayesOpt.ipynb">github</a>
				</p>
				<p>
					Fraud detection (Summarizing Konstantin Yakovlev’s view of this competition):
					<a href="https://www.kaggle.com/c/ieee-fraud-detection/discussion/107697#latest-630007">kaggle</a>
				</p>
				<p>
					Fraud detection material/comps in Kaggle:
					<a href="https://www.kaggle.com/c/ieee-fraud-detection/discussion/99987">kaggle</a>
				</p>
				<p>
					Anomaly Detection Isolation Forest&Visualization (iForest):
					<a href="https://www.kaggle.com/adithya44/anomaly-detection-isolation-forest-visualization">kaggle</a>
				</p>
				<p>
					Anomaly Detection with Time Series Forecasting (SARIMA, LSTM, Holtwinters):
					<a href="https://www.kaggle.com/adithya44/anomaly-detection-with-time-series-forecasting">kaggle</a>
				</p>
				<p>
					Time Series Classification and Clustering:
					<a href="https://github.com/alexminnaar/time-series-classification-and-clustering">github</a>
				</p>
				
				<hr>
					
				<h3>
					Selected videos on DS
				</h3>
				<p>
					Flexibility, Interpretability, and Scalability in Time Series Modeling:
					<a href="https://www.youtube.com/watch?v=LkoriFtcRss">youtube</a>
				</p>
				<p>
					kalman filters for non rocket scientists:
					<a href="https://www.youtube.com/watch?v=k_MpfzMc9PU">youtube</a>
				</p>
				<p>
					Стас Семенов tinkoff:
					<a href="https://www.youtube.com/watch?v=NVKDSNM702k">youtube</a>
				</p>
				<p>
					Kaggle BNP Paribas — Станислав Семенов:
					<a href="https://www.youtube.com/watch?v=g335THJxkto">youtube</a>
				</p>
				<p>
					(PCA) Machine Learning for Real-Time Anomaly Detection in Network Time-Series Data:
					<a href="https://www.youtube.com/watch?v=0PqzukqMcdA">youtube</a>
				</p>
			</div>
		</div>
		
		<div class="page-3">
			<div class="container">	
				<div class="row">
					<div class="twelve col tit">
						<h1>
							Anomaly detection benchmarks
						</h1>
					</div>
				</div>
				<h5>
					PCoE Datasets (NASA)
				</h5>
				<p>
					The Prognostics Data Repository is a collection of data sets that have been donated by various universities, agencies, or companies. The data repository focuses exclusively on prognostic data sets, i.e., data sets that can be used for development of prognostic algorithms. Mostly these are time series of data from some nominal state to a failed state. The collection of data in this repository is an ongoing process.
					<a href="https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/">link</a>
				</p>
				<h5>
					(intrusion) KDD Cup 1999 Data
				</h5>
				<p>
					The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between ``bad'' connections, called intrusions or attacks, and ``good'' normal connections.
					<a href="http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html">link</a>
				</p>
				<h5>
					Datasets for Concept Drift
				</h5>
				<p>
					Малополезный ресурс, есть данные по KDD Cup 1999 Data
					<a href="http://www.liaad.up.pt/kdus/products/datasets-for-concept-drift">link</a>
				</p>
				<h5>
					Delft pump
				</h5>
				<p>
					The Delft pump dataset, with some description in A. Ypma, Learning methods for machine vibration analysis and health monitoring, thesis Delft university of Technology, 2001.
				</p>
				<ul>
					<li><a href="http://homepage.tudelft.nl/n9d04/occ/index.html">main link</a>
				</ul>
				<h5>
					Simple Nonlinear System
				</h5>
				<p>
					The simple simulated nonlinear system (Shao et al. 2009) consists of three variables and two degrees of freedom.
				<ul>
					<li>main link (includes TE process too): Shao, J.-D., Rong, G., & Lee, J. M. (2009). Generalized orthogonal locality preserving projections for nonlinear fault detection and diagnosis. Chemometrics and Intelligent Laboratory Systems, 96(1), 75–83.
					<li>aldrich2013
				</ul>
				</p>
				<h5>
					Tennessee Eastman (TE) process
				</h5>
				<p>
					The Tennessee Eastman process is a well-known simulated chemical process developed to provide a realistic industrial process on which to evaluate the performance of process control and monitoring methods (Russell et al. 2000b). The Eastman Chemical Company created a simulation of an actual chemical process with five major units and eight components (Downs and Vogel 1993).
				</p>
				<ul>
					<li>main link: Downs, J. J., & Vogel, E. F. (1993). A plant-wide industrial process control problem. Computers and Chemical Engineering, 17(3), 245–255.
					<li>1. Russell, E. L., Chiang, L. H., & Braatz, R. D. (2000b). Fault detection in industrial processes using canonical variate analysis and dynamic principal component analysis. Chemometrics and Intelligent Laboratory Systems, 51(1), 81–93.
					<li>2. aldrich2013
					<li><a href="http://depts.washington.edu/control/LARRY/TE/download.html">TE generator for matlab</a>
				</ul>
				<h5>
					Sugar Refinery Benchmark
				</h5>
				<p>
					A fault detection and identification benchmark was developed by the Development and Application Methods for Diagnosis of Actuators in Industrial Controls Systems (DAMADICS) research training network (DAMADICS RTN 2002).
					This benchmark is based on a real sugar refinery (Cukrownia Lublin SA) in Poland, where three actuators have been modified to allow the introduction of mechanically and electrically induced faults (Bartys ́ et al. 2006). Faults were introduced under supervised conditions to prevent the sugar factory from operating outside acceptable quality limits. Both simulated models and real data are available as benchmark data for fault detection and identification. Detailed information, simulators and process data of this benchmark is available from the DAMADICS research group website (DAMADICS RTN 2002).
				</p>
				<ul>
					<li>Bartys ́, M., & Syfert, M. (2002). Lublin sugar factory data description file. Institute of Automatic Control and Robotics – Warsaw University of Technology. Available at: <a href="http://diag.mchtr.pw.edu.pl/damadics/download/Lublin/damadics-lublin-data-description-v02March2002.zip">link</a>
					
					<li>Bartys ́, M., Patton, R., Syfert, M., de las Heras, S., & Quevedo, J. (2006). Introduction to the DAMADICS actuator FDI benchmark study. Control Engineering Practice, 14(6), 577–596.
					
					<li>DAMADICS RTN. (2002). DAMADICS RTN information web site. Institute of Automatic Control and Robotics – Warsaw University of Technology. Available at: <a href="http://diag.mchtr.pw.edu.pl/damadics/">link</a>
				</ul>
				<h5>
					Multi-hop Outdoor Real Data (MHORD) | Multi-hop Indoor Real Data (MHIRD) | Single-hop Outdoor Real Data (SHORD) | Single-hop Indoor Real Data (SHIRD)
				</h5>
				<p>
					These data sets were collected from a simple single-hop and a multi-hop wireless sensor network deployment using TelosB motes. Each data set consists of correlated process parameters (e.g. humidity and temperature) collected during a 6-hour period at intervals of 5 s. The Single-hop data was collected on 9th May 2010, and the multi-hop data was collected on 10th July 2010.
				</p>
				<ul>
					<li>first link: S. Suthaharan, M. Alzahrani, S. Rajasegarar, C. Leckie, and M. Palaniswami, ‘‘Labelled data collection for anomaly detection in wireless sensor networks,’’ in Proc. 6th Int. Conf. Intell. Sensors, Sensor Netw. Inform. Process. (ISSNIP), Dec. 2010, pp. 269–274.					
					<li>A. Fahad, Z. Tari, A. Almalawi, A. Goscinski, I. Khalil, and A. Mahmood, ‘‘PPFSCADA: Privacy preserving framework for SCADA data publishing,’’ Future Generat. Comput. Syst., vol. 37, pp. 496–511, Jul. 2014.
				</ul>
				<h5>
					(intrusion) simulated spoofing attack for SCADA system (detonated as SPFDS) | simulated denial of service attack DOS for SCADA system (detonated as DOSDS) | simulated of both spoofing and attacks for SCADA system (detonated as SPDOS)
				</h5>
				<p>
					
				</p>
				<ul>
					<li>A.Almalawi, Z.Tari, A.Fahad and I.Khalil,‘‘A framework for improving the accuracy of unsupervised intrusion detection for SCADA systems,’’ in Proc. 12th IEEE Int. Conf. Trust, Security Privacy Comput. Commun. (TrustCom), Jul. 2013, pp. 292–301.					
					<li>A.Almalawi, Z.Tari, I.Khalil and A.Fahad,‘‘SCADAVT-A framework for SCADA security testbed based on virtualization technology,’’ in Proc. IEEE 38th Conf. Local Comput. Netw. (LCN), Oct. 2013, pp. 639–646.
				</ul>
				<h5>
					(intrusion) DARPA
				</h5>
				<p>
					Since 1999, the DARPA99 data has been the most widely used data set for the IDS evaluations that use machine learning techniques. This data set was prepared by Stolfo et al. [50] and is built based on the data captured in the DARPA99 IDS evaluation program [51]. This data set contains raw traffic flow records with an associated label to indicate whether the record was labeled as either normal or an attack. In particular, the simulated attacks fall in one of the most common types of attacks including: a Denial of Service Attack (DoS), User to Root Attack (U2R), Remote to Local Attack (R2L) and a Probing Attack. The original DARPA data sets is about 4 GB of compressed raw (binary) tcpdump data of 7 weeks of network traffic, which can be processed into about 5 million connection records, each with about 100 bytes. 
					This sample data set consists of approximately 10,000 single connection vectors each of which contains 41 attributes.
				</p>
				<ul>
					<li>[50] S.Stolfo,W.Fan,W.Lee,A.Prodromidis,P.Chan,Cost-basedmodelingforfraud and intrusion detection: results from the jam project, in: DARPA Information Survivability Conference and Exposition, 2000, DISCEX’00, Proceedings, vol. 2, IEEE, 2000, pp. 130–144.				
					<li>[51] R. Lippmann, D. Fried, I. Graf, J. Haines, K. Kendall, D. McClung, D. Weber, S. Webster, D. Wyschogrod, R. Cunningham, et al. Evaluating intrusion detection systems: the 1998 DARPA off-line intrusion detection evaluation, in: DARPA Information Survivability Conference and Exposition, 2000, DISCEX’00, Proceedings, vol. 2, IEEE, 2000, pp. 12–26.
				</ul>
				<h5>
					water treatment plant (WTP)
				</h5>
				<p>
					This data set was collected from the daily measures of sensors in a urban waste water treatment plant. The objective is to classify the operational state of the plant in order to identify the abnormality through the state variables of the plant at each of the stages of the treatment process. This data set consists of 527 instances and each instance contains 38 attributes and is labeled either normal or abnormal.
				</p>
				<ul>
					<li><a href="https://archive.ics.uci.edu/ml/datasets/water+treatment+plant">link to downloading</a>
					<li><a href="docs/water-treatment.txt">variables descriptions</a>
					<li>where to read about: A. Fahad, Z. Tari, A. Almalawi, A. Goscinski, I. Khalil, and A. Mahmood, ‘‘PPFSCADA: Privacy preserving framework for SCADA data publishing,’’ Future Generat. Comput. Syst., vol. 37, pp. 496–511, Jul. 2014.
				</ul>
				<h5>
					(intrusion) Internet Traffic Data (ITD)
				</h5>
				<p>
					the traffic data sets collected by the high-performance network monitor (described in [49]) are some of the largest publicly available network traffic traces that are used in our experiment. These data sets are based on traces captured using its loss-limited, full-payload capture to disk where timestamps with a resolution of better than 35 ns are provided. The data were taken for several different periods in time from one site on the Internet. This site is a research- facility which hosts up to 1000 users connected to the Internet via a full-duplex Gigabyte Ethernet link. Full-duplex traffic on this connection was monitored for each traffic set. The site hosts several biology-related facilities, collectively referred to as Genome Campus (Cambridge Lab). There are three institutions on-site that employ about 1,000 researchers, administrators and technical staff. This campus is connected to the Internet via a full-duplex Gigabyte Ethernet link. It was on this connection to the Internet that the monitor was placed. Each traffic set consists of a full 24 h, week-day period in both link directions.
				</p>
				<ul>
					<li>[49] A. Moore, J. Hall, C. Kreibich, E. Harris, I. Pratt, Architecture of a network monitor, in: Passive & Active Measurement Workshop 2003, PAM2003, Citeseer, 2003.
				</ul>
				<h5>
					The Numenta Anomaly Benchmark (NAB)
				</h5>
				<p>
					The NAB corpus of 58 timeseries data files is designed to provide data for research in streaming anomaly detection. It is comprised of both real-world and artifical timeseries data containing labeled anomalous periods of behavior.

The majority of the data is real-world from a variety of sources such as AWS server metrics, Twitter volume, advertisement clicking metrics, traffic data, and more. All data is included in the repository, with more details in the <a href="https://github.com/numenta/NAB/tree/master/data">data readme</a>.
				</p>
				<ul>
					<li>Please cite the following publication when referring to NAB:
Ahmad, S., Lavin, A., Purdy, S., & Agha, Z. (2017). Unsupervised real-time anomaly detection for streaming data. Neurocomputing, Available online 2 June 2017, ISSN 0925-2312, https://doi.org/10.1016/j.neucom.2017.04.070
					<li><a href="https://numenta.com/blog/2016/08/10/numenta-anomaly-benchmark-nab-competition-2016-winners/">2016 numenta competition results</a>
				</ul>
				<h5>
					Spacecraft Anomaly Data
				</h5>
				<p>
					Anomaly events range from minor operational problems which can be easily corrected to permanent spacecraft failures. The database includes spacecraft anomalies in interplanetary space and in near-earth orbit; the majority of the data comes from geostationary spacecraft.
				</p>
				<ul>
					<li>Description: 
						<a href="https://www.kaggle.com/usaf091847/spacecraft-anomaly-data">kaggle</a>
					<li>These data are courtesy of NGDC (now National Centers for Environmental Information, NCEI). 
						<a href="https://www.ngdc.noaa.gov/stp/satellite/anomaly/satelliteanomaly.html">link to downloading</a>
				</ul>
				<h5>
					S5 - A Labeled Anomaly Detection Dataset, version 1.0(16M)
				</h5>
				<p>
					Automatic anomaly detection is critical in today's world where the sheer volume of data makes it impossible to tag outliers manually. The goal of this dataset is to benchmark your anomaly detection algorithm. The dataset consists of real and synthetic time-series with tagged anomaly points. The dataset tests the detection accuracy of various anomaly-types including outliers and change-points.
				</p>
				<ul>
					<li><a href="https://webscope.sandbox.yahoo.com/catalog.php?datatype=s&did=70">link to yahoo</a>
				</ul>
				<h5>
					KPI dataset from AIOPS data competition
				</h5>
				<p>
					KPI is released by AIOPS data competition. The dataset consists of multiple KPI curves with anomaly labels collected from various Internet Companies, including Sogou, Tecent, eBay, etc. Most KPI curves have an interval of 1 minute between two adjacent data points, while some of them have an interval of 5 minutes.
				</p>
				<ul>
					<li><a href="http://iops.ai/competition_detail/?competition_id=5&flag=1">link to competition rules and leaderboard</a>
					<li><a href="http://iops.ai/dataset_detail/?id=10">link to dataset downloading</a>
					<li><a href="https://arxiv.org/pdf/1906.03821.pdf">link to arxiv paper with description and methods comparing</a>
					<li><a href="https://github.com/iopsai/iops/tree/master/evaluation">link to github</a>
				</ul>
				<h5>
					Microsoft
				</h5>
				<p>
					Microsoft is a dataset obtained from our internal anomaly de- tection service at Microsoft. We select a collection of time-series randomly for evaluation. The selected time-series reflect different KPIs, including revenues, active users, number of pageviews, etc. The anomaly points are labeled by customers or editors manually; and the interval of these time-series is one day.
				</p>
				<ul>
					<li>proprietary dataset
					<li><a href="https://arxiv.org/pdf/1906.03821.pdf">microsoft arxiv paper with dataset description</a>
				</ul>
				<h5>
					Supplementary material concerning repeatability
				</h5>
				<p>
					All datasets used in the following experiments can be downloaded here:
				</p>
				<ul>
					<li><a href="https://www.ipd.kit.edu/mitarbeiter/muellere/HiCS/">all 21 synthetic and real world datasets</a>
				</ul>
				<h5>
					N-BaIoT: Data for network based detection of IoT botnet attacks
				</h5>
				<p>
					This dataset addresses the lack of public botnet datasets, especially for the IoT. It suggests *real* traffic data, gathered from 9 commercial IoT devices authentically infected by Mirai and BASHLITE.
				</p>
				<ul>
					<li><a href="https://archive.ics.uci.edu/ml/datasets/detection_of_IoT_botnet_attacks_N_BaIoT#">site</a>
					
				</ul>
			</div>
		</div>
		
		<div class="page-4">
			<div class="container">
				<div class="row">
					<div class="twelve col tit">
						<h1>
							Thesis
						</h1>
					</div>
				</div>
				<h5>
					bayesian_changepoint_detection (online)
				</h5>
				<p>
					Github repository with code
					<a href="https://github.com/hildensia/bayesian_changepoint_detection/tree/master/bayesian_changepoint_detection">link</a>
				</p>
				<h5>
					Anomaly Detection and related Software
				</h5>
				<p>
					List of tools & datasets for anomaly detection on time-series data.
					<a href="https://github.com/rob-med/awesome-TS-anomaly-detection">github</a>
				</p>
				<h5>
					Applying random forests and deep encoder-decoder RNNs to time series prediction + few anomaly detection links
				</h5>
				<p>
					Playing with electricity - forecasting 5000 time series
					<a href="https://spark-in.me/post/playing-with-electricity">spark-in.me</a>
				</p>
				<h5>
					Python Outlier Detection (PyOD)
				</h5>
				<p>
					A Python Toolbox for Scalable Outlier Detection (Anomaly Detection)
					
					<a href="https://pyod.readthedocs.io/en/latest/">site with all related materials</a> | 
					<a href="https://github.com/yzhao062/Pyod#aggarwal2015theoretical">github with all related materials</a>
				</p>
			</div>
		</div>

		
	</body>
</html>
